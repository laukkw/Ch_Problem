https://www.koolearn.com/dict/tag_1395_1.html



我们所爬取的是这个网页上的数据 

它是不仅有单词 还是有 词性 和意思的 并且会有短语和句子让你更加方便记忆, 我们先把它爬出来写入文件中  

它


记一下思路  先来看一下 我之前写过的爬虫 


main 函数卆 用来传递一下  页码数   执行 toWork 函数 



现在我的思路是这样的


首先我要爬取的页面是二级页面 在第一级的页面有所有的单词.单词对应的url 是他们的词性与意思


我先循环解析出第一个页面 然后使用正则表达式 提取出第二个页面对应的所需内容  就是  wd_ (/d) 6位数字

然后我再创建一个newurl  用它来进行 单词 和意思 和词性的爬取   但是我的newurl 属性的有问题   在我使用 httpGetDB 解析完url 之后 我的newurl 会报 类型错误 

现在我的想法是  再创建一个新的func  把第二部的 new url 放在新的 func 中  那天晚上我这样试过 但是出了问题  

然后再来试一次 

   




现在我新建了一个 func   SpiderPageDBNew  然后 把 第一个 func  SpdierPafeDBNew 的参数传入到 第二个函数中 


现在是4月8 号  现在写好了  第一层的网页连接  就是 获取到每个单词的url 了  现在我需要的是 把这些url 读取并且取出相应的数据  

go 

 现在 我已经把信号添加了  我的想法是 再写一个专门用来爬 我存好的url 的  然后 用包把两个连接起来  

再然后    包装一下  over



线程占用了  

 我来捋一捋  
 

我使用 page 管道来防止提前结束 

我需要的是  先让 sipderpagedb 先执行  我的参数给了一个 page  


爬虫2 第二个参数 是一个 page2 管道  函数结尾  给了一个 idx 给管道赋值了